{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.home()/'.fastai/data/nlp-getting-started'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path/'train.csv')\n",
    "df_test = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add 'keyword' and 'location' also to the sentences with prefixes. But there should be a better way, like handling them as categorical features, instead of like a part of the sentence. \n",
    "\n",
    "BTW, it did not lead to any improvement in the model performance. So the cell below can be commented also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['keyword','location']] = df_train[['keyword','location']].fillna('')\n",
    "df_test[['keyword','location']] = df_test[['keyword','location']].fillna('')\n",
    "\n",
    "# def add_data(r):\n",
    "#     txt = r['text']\n",
    "#     if r['keyword']:\n",
    "#         txt = ' '.join(['xxkeyword',r['keyword'], txt])\n",
    "    \n",
    "#     if (r['location']):\n",
    "#         txt = ' '.join(['xxlocation',r['location'], txt])\n",
    "#     return txt\n",
    "\n",
    "# df_train['text2'] = df_train.apply(add_data, axis=1)\n",
    "# df_test['text2'] = df_test.apply(add_data, axis=1)\n",
    "\n",
    "# for d in [df_train, df_test]:\n",
    "#     d.rename({'text': 'text_org', 'text2': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>.@NorwayMFA #Bahrain police had previously died in a road accident they were not killed by explosion https://t.co/gFJfgTodad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>I still have not heard Church Leaders of Kenya coming forward to comment on the accident issue and disciplinary measures#ArrestPastorNganga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            text\n",
       "100                 .@NorwayMFA #Bahrain police had previously died in a road accident they were not killed by explosion https://t.co/gFJfgTodad\n",
       "101  I still have not heard Church Leaders of Kenya coming forward to comment on the accident issue and disciplinary measures#ArrestPastorNganga"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train[['text']], df_test[['text']]], axis=0)\n",
    "df.iloc[100:110].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj sleeping xxmaj with xxmaj sirens - xxmaj iris ( goo xxmaj goo xxmaj dolls xxmaj cover ) http : / / t.co / xxunk xxbos xxmaj beyonce xxmaj is my pick for http : / / t.co / nnmqlz91o9 xxmaj fan xxmaj army # xxmaj beyhive http : / / t.co / o91f3cyy0r xxunk xxbos xxmaj the annihilation of xxmaj jeb xxmaj christie &amp; &amp; xxmaj xxunk is less than</td>\n",
       "      <td>xxmaj sleeping xxmaj with xxmaj sirens - xxmaj iris ( goo xxmaj goo xxmaj dolls xxmaj cover ) http : / / t.co / xxunk xxbos xxmaj beyonce xxmaj is my pick for http : / / t.co / nnmqlz91o9 xxmaj fan xxmaj army # xxmaj beyhive http : / / t.co / o91f3cyy0r xxunk xxbos xxmaj the annihilation of xxmaj jeb xxmaj christie &amp; &amp; xxmaj xxunk is less than 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: ' people who have been forced to leave their country in order to escape war xxunk or natural disaster ' xxbos xxunk _ xxmaj my xxmaj xxunk will be devastated lol # xxunk xxbos xxmaj we rescued my dog at least 9 years ago ? ? she 's old but still sweet as ever ? ? @zak_bagans http : / / t.co / xxunk xxbos xxmaj police investigating after an e</td>\n",
       "      <td>' people who have been forced to leave their country in order to escape war xxunk or natural disaster ' xxbos xxunk _ xxmaj my xxmaj xxunk will be devastated lol # xxunk xxbos xxmaj we rescued my dog at least 9 years ago ? ? she 's old but still sweet as ever ? ? @zak_bagans http : / / t.co / xxunk xxbos xxmaj police investigating after an e -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "text_transform_block = TextBlock.from_df(text_cols=[text_col], is_lm=True)\n",
    "\n",
    "# DataBlock is a \"Generic container to quickly build `Datasets` and `DataLoaders`\"\n",
    "# In other words, it contains the 'blocks of transformations to x andy', how to get x, \n",
    "# how to get y and how to split them. We create a dataloader out of it by providing \n",
    "# the datasource and batch size. \n",
    "\n",
    "lm_dl = DataBlock(\n",
    "    blocks=text_transform_block,\n",
    "    get_x=attrgetter(text_col),\n",
    "    splitter=RandomSplitter()\n",
    ").dataloaders(df, bs=128, seq_len=72)\n",
    "\n",
    "lm_dl.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len:  5832\n"
     ]
    }
   ],
   "source": [
    "print('vocab len: ', len(lm_dl.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#2) [Tokenizer: (str,object) -> encodes\n",
      "(Path,object) -> encodes (object,object) -> decodes,Numericalize: (object,object) -> encodes (object,object) -> decodes]\n",
      "(#1) [<class 'fastai2.data.transforms.ToTensor'>]\n",
      "(#0) []\n"
     ]
    }
   ],
   "source": [
    "print(text_transform_block.type_tfms)\n",
    "print(text_transform_block.item_tfms)\n",
    "print(text_transform_block.batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.407336</td>\n",
       "      <td>4.234660</td>\n",
       "      <td>69.038216</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.607827</td>\n",
       "      <td>3.434359</td>\n",
       "      <td>31.011522</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.093230</td>\n",
       "      <td>3.223242</td>\n",
       "      <td>25.109388</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.743704</td>\n",
       "      <td>3.129892</td>\n",
       "      <td>22.871511</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.507817</td>\n",
       "      <td>3.088863</td>\n",
       "      <td>21.952103</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.321668</td>\n",
       "      <td>3.064706</td>\n",
       "      <td>21.428164</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.194085</td>\n",
       "      <td>3.057027</td>\n",
       "      <td>21.264252</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.109205</td>\n",
       "      <td>3.055584</td>\n",
       "      <td>21.233576</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(lm_dl, AWD_LSTM, metrics=Perplexity())\n",
    "learn.fit_one_cycle(8, 2e-2, moms=(0.8, 0.7, 0.8))\n",
    "learn.save('epoch_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.949537</td>\n",
       "      <td>2.986506</td>\n",
       "      <td>19.816313</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.867903</td>\n",
       "      <td>2.954794</td>\n",
       "      <td>19.197765</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.752208</td>\n",
       "      <td>2.929241</td>\n",
       "      <td>18.713421</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.671687</td>\n",
       "      <td>2.931930</td>\n",
       "      <td>18.763807</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, 2e-3)\n",
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add 'location' and 'keyword' to the text with unique keywords as prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#2) [Tokenizer: (str,object) -> encodes\n",
      "(Path,object) -> encodes (object,object) -> decodes,Numericalize: (object,object) -> encodes (object,object) -> decodes]\n",
      "(#1) [<class 'fastai2.data.transforms.ToTensor'>]\n",
      "(#0) []\n"
     ]
    }
   ],
   "source": [
    "clf_tranform_blocks = [TextBlock.from_df(text_cols=['text'], vocab=lm_dl.vocab), CategoryBlock]\n",
    "\n",
    "print(clf_tranform_blocks[0].type_tfms)\n",
    "print(clf_tranform_blocks[0].item_tfms)\n",
    "print(clf_tranform_blocks[0].batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: partial\n",
      "Setting up after_batch: Pipeline: \n"
     ]
    }
   ],
   "source": [
    "clf_dl = DataBlock(\n",
    "    blocks=clf_tranform_blocks,\n",
    "    get_x=attrgetter('text'),\n",
    "    get_y=attrgetter('target'),\n",
    "    splitter=RandomSplitter(0.1)\n",
    ").dataloaders(df_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos _ \\n▁ xxrep 5 ? xxup retweet \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup follow xxup all xxup who xxup rt \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup xxunk \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup gain xxup with \\n▁ xxrep 7 ? \\n▁ xxrep 5 ? xxup follow ? xxunk # xxup xxunk \\n▁ # xxup ty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxup info xxup s. xxup wnd : xxunk / 6 . xxup xxunk : xxup xxunk xxup xxunk . xxup exp xxup inst xxup apch . xxup rwy 05 . xxup curfew xxup in xxup oper xxup until 2030 xxup z. xxup taxiways xxup foxtrot 5 &amp; &amp; xxup foxtrot 6 xxup navbl . xxup tmp : 10 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_dl.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.672690</td>\n",
       "      <td>0.492945</td>\n",
       "      <td>0.768725</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.625081</td>\n",
       "      <td>0.478833</td>\n",
       "      <td>0.777924</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = text_classifier_learner(clf_dl, AWD_LSTM, path=path, metrics=accuracy)\n",
    "learn = learn.load_encoder('finetuned')\n",
    "\n",
    "learn.fit_one_cycle(2, 2e-2, moms=(0.8, 0.7, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.562895</td>\n",
       "      <td>0.478458</td>\n",
       "      <td>0.791064</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.464479</td>\n",
       "      <td>0.482533</td>\n",
       "      <td>0.792378</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(2, slice(1e-2/(2.6**4),1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.429314</td>\n",
       "      <td>0.470474</td>\n",
       "      <td>0.804205</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.352418</td>\n",
       "      <td>0.510408</td>\n",
       "      <td>0.797635</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(2, slice(5e-3/(2.6**4),5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.793693</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272631</td>\n",
       "      <td>0.567236</td>\n",
       "      <td>0.789750</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.236880</td>\n",
       "      <td>0.594942</td>\n",
       "      <td>0.805519</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.222788</td>\n",
       "      <td>0.607421</td>\n",
       "      <td>0.798949</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-3/(2.6**4),1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('tuned_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner('/home/achinta/.fastai/data/nlp-getting-started/tuned_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = learn.dls.test_dl(df_test)\n",
    "inp, preds, x, dec_preds = learn.get_preds(dl=test_dl, with_input=True, with_decoded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the predictions are not the same order as in the dataframe** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\n",
    "    'id': df_test.iloc[test_dl.get_idxs()]['id'],\n",
    "    'target': dec_preds\n",
    "}).sort_values('id')\n",
    "\n",
    "output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|##########| 22.2k/22.2k [00:09<00:00, 2.35kB/s]\n",
      "Successfully submitted to Real or Not? NLP with Disaster Tweets"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c nlp-getting-started -f output.csv -m 'added location and target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave a leaderboard score of 0.80572 (1251/3337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach B: Expanding abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://www.kaggle.com/rftexas/text-only-kfold-bert\n",
    "with open('abbreviations.json','r') as f:\n",
    "    abbreviations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySpacyTokenizer(SpacyTokenizer):\n",
    "    def __init__(self, lang='en', special_toks=None, buf_sz=5000):\n",
    "        super().__init__(lang, special_toks, buf_sz)\n",
    "        self.abbr = abbreviations\n",
    "\n",
    "    def __call__(self, items):\n",
    "        # replace abbreviation with ites expansion fo \n",
    "        if self.abbr:\n",
    "            items2 = [' '.join([abbreviations.get(o, o) for o in item.split()]) for item in items]\n",
    "        else:\n",
    "            items2 = items\n",
    "        return super().__call__(items2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5816\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "text_transform_block = TextBlock.from_df(text_cols=[text_col], tok_func=MySpacyTokenizer, is_lm=True)\n",
    "\n",
    "# DataBlock is a \"Generic container to quickly build `Datasets` and `DataLoaders`\"\n",
    "# In other words, it contains the 'blocks of transformations to x andy', how to get x, \n",
    "# how to get y and how to split them. We create a dataloader out of it by providing \n",
    "# the datasource and batch size. \n",
    "\n",
    "lm_dl = DataBlock(\n",
    "    blocks=text_transform_block,\n",
    "    get_x=attrgetter(text_col),\n",
    "    splitter=RandomSplitter()\n",
    ").dataloaders(df, bs=256, seq_len=72)\n",
    "print(len(lm_dl.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.594144</td>\n",
       "      <td>4.666418</td>\n",
       "      <td>106.316193</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.945578</td>\n",
       "      <td>3.655969</td>\n",
       "      <td>38.705025</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.435383</td>\n",
       "      <td>3.391801</td>\n",
       "      <td>29.719433</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.091724</td>\n",
       "      <td>3.291511</td>\n",
       "      <td>26.883455</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.860700</td>\n",
       "      <td>3.234438</td>\n",
       "      <td>25.392101</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.685889</td>\n",
       "      <td>3.209291</td>\n",
       "      <td>24.761511</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.554682</td>\n",
       "      <td>3.195355</td>\n",
       "      <td>24.418839</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.459992</td>\n",
       "      <td>3.192690</td>\n",
       "      <td>24.353861</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(lm_dl, AWD_LSTM, metrics=Perplexity())\n",
    "learn.fit_one_cycle(8, 2e-2, moms=(0.8, 0.7, 0.8))\n",
    "learn.save('lm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.075059</td>\n",
       "      <td>3.096713</td>\n",
       "      <td>22.125113</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.046757</td>\n",
       "      <td>3.105889</td>\n",
       "      <td>22.329067</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.972030</td>\n",
       "      <td>3.038295</td>\n",
       "      <td>20.869637</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.903151</td>\n",
       "      <td>3.030007</td>\n",
       "      <td>20.697374</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.load('lm_1')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, 2e-3)\n",
    "learn.save('lm_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.794242</td>\n",
       "      <td>3.019825</td>\n",
       "      <td>20.487705</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.782044</td>\n",
       "      <td>3.009561</td>\n",
       "      <td>20.278502</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.763209</td>\n",
       "      <td>3.008280</td>\n",
       "      <td>20.252531</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.727956</td>\n",
       "      <td>3.003245</td>\n",
       "      <td>20.150814</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.load('lm_2')\n",
    "learn.fit_one_cycle(4, 1e-3)\n",
    "learn.save('lm_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('abbr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5816"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_dl.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#2) [Tokenizer: (str,object) -> encodes\n",
      "(Path,object) -> encodes (object,object) -> decodes,Numericalize: (object,object) -> encodes (object,object) -> decodes]\n",
      "(#1) [<class 'fastai2.data.transforms.ToTensor'>]\n",
      "(#0) []\n"
     ]
    }
   ],
   "source": [
    "clf_tranform_blocks = [TextBlock.from_df(text_cols=['text'], tok_func=MySpacyTokenizer, vocab=lm_dl.vocab), CategoryBlock]\n",
    "\n",
    "print(clf_tranform_blocks[0].type_tfms)\n",
    "print(clf_tranform_blocks[0].item_tfms)\n",
    "print(clf_tranform_blocks[0].batch_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: partial\n",
      "Setting up after_batch: Pipeline: \n"
     ]
    }
   ],
   "source": [
    "clf_dl = DataBlock(\n",
    "    blocks=clf_tranform_blocks,\n",
    "    get_x=attrgetter('text'),\n",
    "    get_y=attrgetter('target'),\n",
    "    splitter=RandomSplitter(0.05)\n",
    ").dataloaders(df_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : . : xxup retweet xxunk : # xxunk xxmaj indian xxmaj army xxunk _ http : / / t.co / xxunk g</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxmaj rare xxunk into # terror and xxmaj how to fight it http : / / t.co / xxunk # xxmaj cameroon # xxup usa # xxmaj xxunk # xxup xxunk # xxup fr # xxmaj nigeria # xxup uk # xxmaj africa # xxup de # xxup ca # xxup au # xxup jp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_dl.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.719345</td>\n",
       "      <td>0.528575</td>\n",
       "      <td>0.760526</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.671253</td>\n",
       "      <td>0.500551</td>\n",
       "      <td>0.755263</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649146</td>\n",
       "      <td>0.491686</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.644446</td>\n",
       "      <td>0.497334</td>\n",
       "      <td>0.755263</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = text_classifier_learner(clf_dl, AWD_LSTM, path=path, metrics=accuracy)\n",
    "learn = learn.load_encoder('abbr')\n",
    "\n",
    "learn.fit_one_cycle(4, 2e-2, moms=(0.8, 0.7, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.567271</td>\n",
       "      <td>0.450082</td>\n",
       "      <td>0.786842</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.475400</td>\n",
       "      <td>0.448440</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(2, slice(1e-2/(2.6**4),1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.562773</td>\n",
       "      <td>0.471380</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.496642</td>\n",
       "      <td>0.460690</td>\n",
       "      <td>0.797368</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(2, slice(5e-3/(2.6**4),5e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.469011</td>\n",
       "      <td>0.457653</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.450835</td>\n",
       "      <td>0.457642</td>\n",
       "      <td>0.792105</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.444488</td>\n",
       "      <td>0.458775</td>\n",
       "      <td>0.792105</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.433657</td>\n",
       "      <td>0.453173</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-3/(2.6**4),1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.428510</td>\n",
       "      <td>0.457650</td>\n",
       "      <td>0.797368</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.407471</td>\n",
       "      <td>0.461325</td>\n",
       "      <td>0.797368</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.409867</td>\n",
       "      <td>0.448576</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.395462</td>\n",
       "      <td>0.448021</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, slice(1e-3/(2.6**4),1e-4))\n",
    "learn.export('tuned_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|##########| 22.2k/22.2k [00:15<00:00, 1.44kB/s]\n",
      "Successfully submitted to Real or Not? NLP with Disaster Tweets"
     ]
    }
   ],
   "source": [
    "def save_preds():\n",
    "    learn = load_learner('/home/achinta/.fastai/data/nlp-getting-started/tuned_classifier.pkl')\n",
    "    test_dl = learn.dls.test_dl(df_test)\n",
    "    inp, preds, x, dec_preds = learn.get_preds(dl=test_dl, with_input=True, with_decoded=True)\n",
    "    output = pd.DataFrame({\n",
    "        'id': df_test.iloc[test_dl.get_idxs()]['id'],\n",
    "        'target': dec_preds\n",
    "    }).sort_values('id')\n",
    "\n",
    "    output.to_csv('output.csv', index=False)\n",
    "    \n",
    "save_preds()\n",
    "!kaggle competitions submit -c nlp-getting-started -f output.csv -m 'added abbreviations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach C - other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach D - Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 8.2 s, total: 2min 4s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import bcolz\n",
    "glove_path = Path.home()/'data/glove'\n",
    "\n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.300d.dat', mode='w')\n",
    "\n",
    "with open(glove_path/'glove.6B.300d.txt', 'rb') as f:\n",
    "    for idx, l in enumerate(f):\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "        \n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000, 300)), rootdir=f'{glove_path}/6B.300.dat', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors.flush()\n",
    "pickle.dump(words, open(f'{glove_path}/6B.300_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(f'{glove_path}/6B.300_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'{glove_path}/6B.300.dat')[:]\n",
    "words = pickle.load(open(f'{glove_path}/6B.300_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'{glove_path}/6B.300_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create random numpy array and thenload it with glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing words in glove:  450\n"
     ]
    }
   ],
   "source": [
    "emb_np = np.random.rand(len(lm_dl.vocab), 300)\n",
    "missing_vocab = []\n",
    "for idx, word in enumerate(lm_dl.vocab):\n",
    "    if word in glove:\n",
    "        emb_np[idx,:] = glove[word]\n",
    "    else:\n",
    "        missing_vocab.append(word)\n",
    "print('missing words in glove: ', len(missing_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(5832, 300)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = nn.Embedding.from_pretrained(torch.from_numpy(emb_np)); emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As AWD_LSTM does not support pretrained embeddings, lets override it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAWD_LSTM(AWD_LSTM):\n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token=1, hidden_p=0.2, input_p=0.6, embed_p=0.1,\n",
    "             weight_p=0.5, bidir=False):\n",
    "        super().__init__(vocab_sz, emb_sz, n_hid, n_layers, pad_token, hidden_p, input_p, embed_p, weight_p, bidir)\n",
    "        self.encoder = emb\n",
    "    \n",
    "awd_lstm_lm_config['emb_sz'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "text_transform_block = TextBlock.from_df(text_cols=[text_col], tok_func=MySpacyTokenizer, is_lm=True)\n",
    "\n",
    "lm_dl = DataBlock(\n",
    "    blocks=text_transform_block,\n",
    "    get_x=attrgetter(text_col),\n",
    "    splitter=RandomSplitter()\n",
    ").dataloaders(df, bs=256, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SequentialRNN:\n\tsize mismatch for 0.encoder.weight: copying a param with shape torch.Size([5816, 400]) from checkpoint, the shape in current model is torch.Size([5816, 300]).\n\tsize mismatch for 0.encoder_dp.emb.weight: copying a param with shape torch.Size([5816, 400]) from checkpoint, the shape in current model is torch.Size([5816, 300]).\n\tsize mismatch for 0.rnns.0.module.weight_ih_l0: copying a param with shape torch.Size([4608, 400]) from checkpoint, the shape in current model is torch.Size([4608, 300]).\n\tsize mismatch for 0.rnns.2.weight_hh_l0_raw: copying a param with shape torch.Size([1600, 400]) from checkpoint, the shape in current model is torch.Size([1200, 300]).\n\tsize mismatch for 0.rnns.2.module.weight_ih_l0: copying a param with shape torch.Size([1600, 1152]) from checkpoint, the shape in current model is torch.Size([1200, 1152]).\n\tsize mismatch for 0.rnns.2.module.weight_hh_l0: copying a param with shape torch.Size([1600, 400]) from checkpoint, the shape in current model is torch.Size([1200, 300]).\n\tsize mismatch for 0.rnns.2.module.bias_ih_l0: copying a param with shape torch.Size([1600]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for 0.rnns.2.module.bias_hh_l0: copying a param with shape torch.Size([1600]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for 1.decoder.weight: copying a param with shape torch.Size([5816, 400]) from checkpoint, the shape in current model is torch.Size([5816, 300]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-e35951da6e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch_8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/text/learner.py\u001b[0m in \u001b[0;36mlanguage_model_learner\u001b[0;34m(dls, arch, config, drop_mult, pretrained, pretrained_fnames, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntar_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mc_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mfnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'*.{ext}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pkl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/text/learner.py\u001b[0m in \u001b[0;36mload_pretrained\u001b[0;34m(self, wgts_fname, vocab_fname, model)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwgts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Just in case the pretrained model was saved with an optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mwgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwgts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mload_ignore_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/text/learner.py\u001b[0m in \u001b[0;36mload_ignore_keys\u001b[0;34m(model, wgts)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tsize mismatch for 0.encoder.weight: copying a param with shape torch.Size([5816, 400]) from checkpoint, the shape in current model is torch.Size([5816, 300]).\n\tsize mismatch for 0.encoder_dp.emb.weight: copying a param with shape torch.Size([5816, 400]) from checkpoint, the shape in current model is torch.Size([5816, 300]).\n\tsize mismatch for 0.rnns.0.module.weight_ih_l0: copying a param with shape torch.Size([4608, 400]) from checkpoint, the shape in current model is torch.Size([4608, 300]).\n\tsize mismatch for 0.rnns.2.weight_hh_l0_raw: copying a param with shape torch.Size([1600, 400]) from checkpoint, the shape in current model is torch.Size([1200, 300]).\n\tsize mismatch for 0.rnns.2.module.weight_ih_l0: copying a param with shape torch.Size([1600, 1152]) from checkpoint, the shape in current model is torch.Size([1200, 1152]).\n\tsize mismatch for 0.rnns.2.module.weight_hh_l0: copying a param with shape torch.Size([1600, 400]) from checkpoint, the shape in current model is torch.Size([1200, 300]).\n\tsize mismatch for 0.rnns.2.module.bias_ih_l0: copying a param with shape torch.Size([1600]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for 0.rnns.2.module.bias_hh_l0: copying a param with shape torch.Size([1600]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for 1.decoder.weight: copying a param with shape torch.Size([5816, 400]) from checkpoint, the shape in current model is torch.Size([5816, 300])."
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(lm_dl, AWD_LSTM, metrics=Perplexity())\n",
    "learn.fit_one_cycle(8, 2e-2, moms=(0.8, 0.7, 0.8))\n",
    "learn.save('epoch_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate(dl=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train.location.unique()))\n",
    "print(df_train.location.unique()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl.get_idxs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dl.get_idxs()))\n",
    "test_dl.get_idxs()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, dec_preds = learn.get_preds(dl=test_dl, with_input=True, with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_oneshot = pd.DataFrame({\n",
    "    'id': df_test.iloc[test_dl.get_idxs()]['id'],\n",
    "    'preds_oneshot': dec_preds\n",
    "}).sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_oneshot.iloc[100:120].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.iloc[100:120].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = output.join(output_oneshot, on='id',lsuffix='_l', rsuffix='_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastcore.foundation.PrePostInitMeta"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AWD_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
